{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4affb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7c59f",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6328c4",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c19cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "data_load = pd.read_csv(\"file.csv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2878ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns\n",
    "data_load = pd.read_csv(\"file.csv\", sep = '\\t', usecols = ['col1', 'col2'])\n",
    "data_load = pd.read_csv(\"file.csv\", sep = '\\t', usecols = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d40fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers of rows\n",
    "data_load = pd.read_csv(\"file.csv\", sep = '\\t', nrows = 1000, header = None)\n",
    "data_load = pd.read_csv(\"file.csv\", sep = '\\t', skiprows = 1000, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a17e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column names\n",
    "col_names = list(data)\n",
    "data_load = pd.read_csv(\"file.csv\", sep = '\\t', header = None, names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a194631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data type\n",
    "data.dtypes\n",
    "data_load = pd.read_csv(\"file.csv\", dtype = {\"col1\" : str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4371496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data\n",
    "data_load = pd.read_csv(\"file.csv\", na_values = {'col1' : 0})\n",
    "print(data_load[data_load.col1.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bf9725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error lines\n",
    "data_load = pd.read_csv(\"file.csv\", error_bad_lines = False, warn_bad_lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef41fea1",
   "metadata": {},
   "source": [
    "### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc19b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "data_load = pd.read_excel(\"file.xlsx\")\n",
    "data_load = pd.read_excel(\"file.xlsx\", sheet_name = 'name')\n",
    "data_load = pd.read_excel(\"file.xlsx\", sheet_name = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns\n",
    "data_load = pd.read_csv(\"file.xlsx\", usecols = ['col1', 'col2'])\n",
    "data_load = pd.read_csv(\"file.xlsx\", usecols = [0,1])\n",
    "data_load = pd.read_csv(\"file.xlsx\", usecols = [\"A:P, R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c513e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows\n",
    "data_load = pd.read_excel(\"file.xlsx\", nrows = 1000)\n",
    "data_load = pd.read_excel(\"file.xlsx\", skiprows = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d09224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean values\n",
    "data_load = pd.read_excel(\"file.xlsx\", true_values = ['yes'], false_values = ['no'])\n",
    "print(bool_data.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing dates (option 1)\n",
    "data_load = pd.read_excel(\"file.xlsx\", parse_dates = ['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing dates (option 2)\n",
    "data_load = pd.to_datetime(data_load['col_date'], format = '%m%d%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b3c709",
   "metadata": {},
   "source": [
    "### Databases\n",
    "\n",
    "Databases should:\n",
    "* Resiliency --> handle routine failures\n",
    "* idempotency --> pipeline can be run multiple times and the output remains the same\n",
    "* scalability --> large amount of data\n",
    "* transparency --> well-tested and documented\n",
    "\n",
    "Characters of a database (in development):\n",
    "* Persistent: makes it easy to rerun a pipeline from the last point of failure instead of from the start.\n",
    "* Data lineage: Documenting the journey that data takes through a data pipeline. --> transparency, trust, start for troubleshooting. \n",
    "* Testing: unit tests, end-to-end testing (small, large, empty and bad files), code review\n",
    "\n",
    "Characters of a database (in production):\n",
    "* Logging/ tracking\n",
    "* Alerting upon retries and failures\n",
    "* Communicate with data consumers\n",
    "\n",
    "SQLAlchemy is a python database engine, which is a library which has tools to work with many major ralation databases."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d0f148b",
   "metadata": {},
   "source": [
    "SQL code\n",
    "\n",
    "SELECT [column_name1, column_name2] \n",
    "FROM [table1] \n",
    "    JOIN [table2]\n",
    "    ON table1.column1 = table2.column2\n",
    "WHERE [condition1] \n",
    "AND [condition2]\n",
    "GROUP BY [value]\n",
    "\n",
    "SELECT DISTINCT [column_names] \n",
    "FROM [table_name] \n",
    "\n",
    "SELECT AVG(name) \n",
    "FROM [table_name] \n",
    "\n",
    "SELECT COUNT(*) \n",
    "FROM [table_name] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: connect to database\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# create database engine to manage connections\n",
    "engine = create_engine('sqlite:///filename.db')\n",
    "\n",
    "# load entire table by table name\n",
    "table = pd.read_sql(query = 'weather', engine = engine)\n",
    "table = pd.read_sql(query = 'SELECT * FROM weather', engine = engine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5bb5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: query database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65705d",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4636ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "data_load = read_json(\"file.json\", orient = 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b171a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d07c3dd6",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20201ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from URL\n",
    "api_url = requests.get(url_string, params, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d723e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dict to string in order to load\n",
    "params = {'term': 'bookstore', 'location' : 'Rotterdam'}\n",
    "headers = {'authorization': 'EMC {}'.format(api_key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data about NYC cafes from the Yelp API\n",
    "response = requests.get(api_url, params = params, headers = headers)\n",
    "\n",
    "# Extract JSON data from the response - returns dictionary\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ff6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract JSON data from the response\n",
    "bookstores = pd.DataFrame(data['businesses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten data and load into dataframe\n",
    "bookstores = json_normalize(data['businesses'], sep = '_')\n",
    "bookstores = json_normalize(data['businesses']\n",
    "                           , sep = '_'\n",
    "                           , record_path = 'categories'\n",
    "                           , meta = [\n",
    "                                'name'\n",
    "                                , 'alias'\n",
    "                                , 'rating'\n",
    "                                , ['coordinates', 'latitude']\n",
    "                                , ['coordinates', 'longitude']\n",
    "                           ]\n",
    "                           , meta_prefix = 'biz_'\n",
    "                           , params['offset'] = 20)\n",
    "\n",
    "print(list(bookstores))\n",
    "print(bookstores.categories) # still nested (=deeply nested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c835e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
