
----------------------------------------- COMMAND OVERVIEW --------------------------------------------
$ pwd
$ ls 		-R -F . ~
$ cd 		. ~
$ cp 		exist
$ mv		new_dir
$ rmdir 
$ rm		-r		
$ mkdir 
$ cat
$ more
$ less		:? :n :q
$ head		-n
$ tail		-n
$ history
$ !<command>
$ cut		-d -f
$ grep		-c -h -i -l -n -v
$ paste
$ wc		-c -w -l
$ sort		-n -r -b -f
$ uniq

--------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------


----------------------------------------- WALK AROUND DIRECTORIES --------------------------------------------

.  -> refers to your current locations
.. -> refers to the directory above your current locations

Absolute path
$ pwd

List files in directory
$ ls
$ ls -R -F

List home directory
$ ls .

List of home directory
$ ls ~

Move around a file
$ cd

Move to current dir (no effect)
$ cd .

Move to home directory
$ cd ~


----------------------------------------- MANIPULATION FILES --------------------------------------------

Copy
$ cp to_copy.txt name_copy.txt

Copy all files in dir 'not_exist' if 'not_exist' does not yet exist
$ cp dir/to_copy.csv not_exist/name_copy.csv exist

Copy all files in dir 'exist' if 'exist' already exist
$ cp dir/to_copy.csv dir/name_copy.csv exist

Move a file
$ mv file1.csv file2.csv ..
$ mv dir_cur/file1.csv dir/curfile2.csv dir_new

Rename file (if old-course.txt already exist, then cource.txt will be replaced)
$ mv course.txt old-course.txt

Remove a file
$ mv file1.csv file2.csv

Remove a dir (only if it is empty, for safety)
$ rmdir dir
$ rm -r dir

Make a directory
$ mkdir dir_name

Look at the content of a file
$ cat file.txt


----------------------------------------- LOOK INTO FILES --------------------------------------------

Scroll through a page
$ more file.txt

Display 1 page at a time
$ less file.txt
-> page up:   $ :?
-> page down: $ :n
-> quit page: $ :q

Show only the first n lines (default n = 10)(eg. 4 gives 4)
$ head text.txt
$ head -n 4 text.txt

Show only the last n lines (default n = 10)(eg. +7 gives 10+7=17)
$ tail text.txt
$ tail -n +7 text.txt


----------------------------------------- COMMAND LIST --------------------------------------------

Help of a command
$ man command
$ man head
$ man less
-> quit page: $ :q

list of commands you have run recently
$ history

Re-run command line 55 or command
$ !55
$ !head
$ !cut


----------------------------------------- SELECT DATA FROM FILES --------------------------------------------

select columns 2 through 5 and columns 8, using comma as the separator" (f -> fields, d -> delimiter)
$ cut -f 2-5,8 -d , values.csv

Select lines according to what they contain
$ grep <containing>
-c: print a count of matching lines rather than the lines themselves
-h: do not print the names of files when searching multiple files
-i: ignore case (e.g., treat "Regression" and "regression" as matches)
-l: print the names of files that contain matches, not the matches
-n: print line numbers for matching lines
-v: invert the match, i.e., only show lines that don't match
<content> : just say what you are searching for


----------------------------------------- COMBINE COMMANDS --------------------------------------------

Combine data files
$ paste file1.csv file2.csv

Output a new file
$ head -n 5 dir/file.csv > new_file.csv

Selection output a new file
$ head -n 5 dir/file.csv | tail-n 3

Pipe the output 
eg $ cut -d , -f 2 seasonal/summer.csv | grep -v Tooth

Count the record (word count: characters (c), word (w), lines (l))
eg $ grep 2017-07 seasonal/spring.csv | wc -l

Wildcards
match zero or more characters	$ *	  eg $ cut -d , -f 1 seasonal/*.csv
match a single character	$ ?	  eg $ 201?.txt will match 2017.txt or 2018.txt, but not 2017-01.txt 
match characters 		$ [...]   eg $ 201[78].txt matches 2017.txt or 2018.txt, but not 2016.txt
match comma-separated patterns	$ {...}   eg $ {*.txt, *.csv} matches any file whose name ends with .txt or .csv, but not files whose names end with .pdf.

Sort data
$ sort name.file
-n : sort numerically
-r : sort reverse order
-b : ignore leading blanks
-f : ignore fold case

Pipeline with cut + grep + sort
$ cut -d , -f 2 seasonal/summer.csv | grep -v Tooth | sort -r

Unique data, remove duplicates
$ uniq
-c : display unique lines with a count how often each occurs

----------------------------------------- BATCH PROCESSING --------------------------------------------

Print a value
$ echo <value>
$ echo $USER
$ echo $HOME
$ echo $PWD
$ echo $SHELL
$ echo $OSTYPE

Create a variable
$ variable=<value/file.csv>

Print variable
$ echo $variable

Repeat a command many times
$ for <variable> in <list>; do <body>; done
eg $ for filetype in gif jpg png; do echo $filetime; done
eg $ for f in seasonal/*.csv; do echo $f; done
eg $ files=seasonal/*.csv
+  $ for f in $files; do echo $f; done

Run many commands
eg $ for file in seasonal/*.csv; do head -n 2 $file | tail -n 1; done
eg $ for file in seasonal/*.csv; do head -n 2 $file ; do echo $file | tail -n 1; done


----------------------------------------- BATCH PROCESSING --------------------------------------------

Edit file
$ nano file.txt

Commands for edit and shortcuts
$ Ctrl + C : Cancel run
$ Ctrl + K : Delete a line
$ Ctrl + U : Undelete a line
$ Ctrl + O : Save Output
$ Ctrl + X : Exit editor

Run a file with a shell command (sh-filetype)
$ bash file.sh

Save bash results in new file
$ bash file.sh > file.out

A script that processes specified files by using $@

	$ cat unique-lines.sh
	output : sort $@ | uniq
	eg $ bash unique-lines.sh seasonal/summer.csv
	eg $ bash unique-lines.sh seasonal/summer.csv seasonal/autumn.csv

	$ cat column.sh
	output: cut -d , -f $2 $1
	explain: $1 = seasonal/autumn.csv, $2 = 1
	eg $ bash column.sh seasonal/autumn.csv 1

	$ cat get-field.sh
	output: [head -n $2 $1 | tail -n 1 | cut -d , -f $3]
	explain: $1 = seasonal/summer.csv, $2 = 4, $3 = 2
	eg $ bash get-field.sh seasonal/summer.csv 4 2

Loops in a shell script

# Print the first and last data records of each file.
	for filename in $@
	do
 	    head -n 2 $filename | tail -n 1
    	    tail -n 1 $filename
	done





